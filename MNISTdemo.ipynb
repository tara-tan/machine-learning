{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit,logit\n",
    "from copy import deepcopy\n",
    "\n",
    "trainFile = r\".\\train-images.idx3-ubyte\"\n",
    "labelFile = r\".\\train-labels.idx1-ubyte\"\n",
    "train = idx2numpy.convert_from_file(trainFile)#simple import (took me half an hour)\n",
    "label = idx2numpy.convert_from_file(labelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(train[1], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(label[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC,abstractmethod\n",
    "class Network(): #refer to the \"documentation\" buried within my notes\n",
    "                #vectorized implementation of a basic neural networks\n",
    "                #TODO add support for other cost functions/activaiton functions\n",
    "                #TODO add support for deleting layers\n",
    "    class Layer():\n",
    "\n",
    "        def __init__(self,network,nodeCount,activationClass,nodePreviousLayer=0):#keep node connections as an array for better performance(to avoid member access overhead)\n",
    "\n",
    "            self.network = network\n",
    "            self._layerCount = len(network._layers)\n",
    "\n",
    "            self._nodeArray = np.zeros(nodeCount,float)#node array\n",
    "\n",
    "            \n",
    "\n",
    "            if(nodePreviousLayer):#if this is not the input layer\n",
    "\n",
    "                self._activation = activationClass._activation #customizable activation function\n",
    "                self._dActivation = activationClass._dActivation\n",
    "\n",
    "                self._weightArray = np.random.rand(nodeCount,len(nodePreviousLayer._nodeArray)) #incoming weights array row = node to go in, column = weights of the node in\n",
    "                self._biasArray = np.zeros(nodeCount)#bias array\n",
    "\n",
    "                self._dBiasArray = np.zeros(nodeCount,float)#derivative of bias\n",
    "                self._dWeightArray = np.zeros([nodeCount, len(nodePreviousLayer._nodeArray)], float)  # derivative of incoming weights\n",
    "                self._dNodeArray = np.zeros(nodeCount,float)#delta array of ∂Activation/∂Node (refer to documentation)\n",
    "                                                            #node = w*incoming + bias\n",
    "                self._prevLayer = nodePreviousLayer #array of previous layer's data #DANGER MAKE SURE IT IS PASSING BY REFERENCE\n",
    "                self._nextLayer : self.Layer #array of next layer's data, assigend/refreshed on connect()\n",
    "\n",
    "        def _forwardProp(self): #TODO change this to support other activation functions\n",
    "            self._nodeArray = np.matmul(self._weightArray,self._prevLayer._nodeArray)+self._biasArray\n",
    "            self._nodeArray = self._activation(self._nodeArray)\n",
    "            \n",
    "        def _backProp(self,isLast = False):#backprop detail refer to \"documentation\"\n",
    "            \n",
    "            if(isLast):#is the last layer\n",
    "                self._dNodeArray = self.network._dCostFunction(self.network._desiredOutput,self._nodeArray) \n",
    "\n",
    "            else:# is any other layer \n",
    "                self._dNodeArray = np.matmul(self._nextLayer._weightArray.T,self._nextLayer._dNodeArray)#the summation (should) is already in matrix multiplication\n",
    "                self._dNodeArray = np.multiply(self._dNodeArray,self._dActivation(self._nodeArray))\n",
    "            temp = np.transpose(self._weightArray)\n",
    "            temp = temp*np.atleast_2d(self._prevLayer._nodeArray).T#I HAVE NO IDEA IF THIS IS CORECT OR NOT HELP\n",
    "            self._dWeightArray += np.transpose(temp)*np.atleast_2d(self._dNodeArray).T# THIS IS SO GOING TO BUG ( it didnt yet i think)\n",
    "            self._dBiasArray += self._dNodeArray#this one is simple tho yay\n",
    "\n",
    "        def _optimize(self,learningRate):\n",
    "            self._weightArray = self._weightArray - self._dWeightArray*learningRate/self.network.totalTrainData\n",
    "            self._biasArray = self._biasArray - self._dBiasArray*learningRate/self.network.totalTrainData\n",
    "            self._nodeArray = self._nodeArray*0\n",
    "\n",
    "        \n",
    "    class Activation(ABC):\n",
    "\n",
    "        @abstractmethod\n",
    "        def _activation(self, inArray):\n",
    "            pass\n",
    "\n",
    "        @abstractmethod\n",
    "        def _dActivation(self, inArray):\n",
    "            pass\n",
    "    \n",
    "    class Sigmoid(Activation):\n",
    "        def _activation(self, inArray):  # sigmoid function\n",
    "            return expit(inArray)\n",
    "\n",
    "        # derivative for the sigmoid, this function takes in the activated output of the layer\n",
    "        def _dActivation(self, inArray):\n",
    "            return np.multiply(inArray, 1-inArray)\n",
    "    \n",
    "    class Relu(Activation):\n",
    "\n",
    "        def _activation(self, inArray):\n",
    "            return np.maximum(inArray,0)\n",
    "        \n",
    "        def _dActivation(self, inArray):\n",
    "            return inArray > 0\n",
    "    \n",
    "    \n",
    "    # class Softmax(Activation):\n",
    "    #     def _activation(self, inArray):\n",
    "    #         return np.exp(inArray)/np.sum(np.exp(inArray))\n",
    "    #     def _dActivation(self, inArray):\n",
    "    #         return super()._dActivation(inArray)\n",
    "    \n",
    "\n",
    "    class MAE():\n",
    "        def _costFunction(self, desired, output):  # cost function, Mean squared error\n",
    "            return np.sum(np.absolute(desired - output))\n",
    "\n",
    "        def _dCostFunction(self, desired, output):\n",
    "            return np.sign(desired - output)\n",
    "\n",
    "    _layers = []\n",
    "    _desiredOutput = []#cached for use in backprop\n",
    "    totalTrainData = 0\n",
    "\n",
    "    def __init__(self, startCount):#start count initializes the first layer\n",
    "        self._layers = []\n",
    "        self._layers.append(self.Layer(self,startCount))\n",
    "\n",
    "    def addLayer(self,nodeCount,activationClass:Activation):#public interface to add new layers (not counting the starting layer)\n",
    "        self._layers.append(self.Layer(self,nodeCount,self._layers[-1]),activationClass)\n",
    "\n",
    "    def setInputLayer(self,inputData):#public interface to set first layer data\n",
    "        self._layers[0]._nodeArray = inputData.copy() \n",
    "\n",
    "    def setCostFunction(self,costClass):\n",
    "        self._costFunction = costClass._costFunction\n",
    "        self._dCostFunction = costClass._dCostFunction\n",
    "\n",
    "    def connect(self): # connects all layers to the next one except first/last one\n",
    "        for i in range(len(self._layers)-2):\n",
    "            self._layers[i+1]._nextLayer = self._layers[i+2]\n",
    "\n",
    "    def trainNetwork(self,desiredAnswer,answer=False):\n",
    "        self._desiredOutput = desiredAnswer.copy()#cached for use in backprop\n",
    "\n",
    "        for i in range(len(self._layers)-1):\n",
    "            self._layers[i+1]._forwardProp()\n",
    "            \n",
    "        if(answer):\n",
    "            return self._layers[-1]._nodeArray\n",
    "        \n",
    "        for i in range(len(self._layers)-1):\n",
    "            self._layers[-i-1]._backProp(True if i == 0 else False)#tell the function that its the last and not to access the out of index element\n",
    "\n",
    "\n",
    "    def optimizeNetwork(self,learningRate):\n",
    "        temp = self._costFunction(self._desiredOutput,self._layers[-1]._nodeArray)\n",
    "        print(temp)\n",
    "        for i in range(len(self._layers)-1):\n",
    "            self._layers[i+1]._optimize(learningRate)\n",
    "\n",
    "        return temp\n",
    "\n",
    "    def getResult(self, desiredAnswerNodes):#calculate the cost\n",
    "        outputNodes=self._layers[-1]._nodeArray\n",
    "        return self._costFunction(desiredAnswerNodes,outputNodes)\n",
    "    \n",
    "    def _costFunction(self, desired, output):#cost function, Mean squared error\n",
    "        print(\"uh oh stinky\")\n",
    "    \n",
    "    def _dCostFunction(self, desired, output):\n",
    "        print(\"uh oh stinky\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m network \u001b[38;5;241m=\u001b[39m \u001b[43mNetwork\u001b[49m(\u001b[38;5;241m784\u001b[39m)\n\u001b[0;32m      2\u001b[0m network\u001b[38;5;241m.\u001b[39maddLayer(\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m      3\u001b[0m network\u001b[38;5;241m.\u001b[39maddLayer(\u001b[38;5;241m256\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Network' is not defined"
     ]
    }
   ],
   "source": [
    "network = Network(784)\n",
    "network.addLayer(256, Network.Relu)\n",
    "network.addLayer(256, Network.Relu)\n",
    "network.addLayer(10, Network.Relu)\n",
    "network.connect()\n",
    "network.setCostFunction(Network.MAE)\n",
    "batch = 2\n",
    "epoch = 1000\n",
    "result = []\n",
    "network.totalTrainData = batch*epoch\n",
    "\n",
    "for ii in range(epoch):\n",
    "    for i in range(batch):\n",
    "        network.setInputLayer(train[i+(ii* batch)].flatten())\n",
    "        hotEncode = np.zeros(10)\n",
    "        hotEncode[label[i+(ii*batch)]] = 1\n",
    "        network.trainNetwork(hotEncode)\n",
    "    result.append(network.optimizeNetwork(0.05))\n",
    "\n",
    "network.setInputLayer(train[1].flatten())\n",
    "hotEncode = np.zeros(10)\n",
    "hotEncode[label[1]] = 1\n",
    "print(network.trainNetwork(hotEncode,True))\n",
    "\n",
    "plt.imshow(train[1], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(result)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
